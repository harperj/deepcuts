\section*{Shot Detection}

Shot boundary detection looks to computationally identify the moments when one shot transitions to another. This is a well studied problem \cite{boreczky1996comparison} \cite{lienhart1998comparison} \cite{lu2013fast} \cite{chavan2014review} and was a primary task in TrecVid's yearly competition \cite{smeaton_video_2010} through 2006. Table \ref{tab:shotdetResults} compares the performance of the best off-the-shelf shot boundary detector, Shotdetect \cite{mathe_shotdetect_2015}, with a ground-truth dataset, allowing for variance of up to 0.4 seconds. 

Based on the results shown in Table \ref{tab:shotdetResults}, we elected to build our own shot detector using state of the art signals and machine learning techniques.

An ideal shot detector has (1) High precision/Recall for both hard and gradual cuts, (2) Robustness to large changes in scene, (3) Robustness to camera motion, \& (4) Consistent location for gradual cuts (e.g. always at the halfway point between to shots).


\begin{center}
  \small{
  \begin{tabular}{ l | r r }
    Movie Clip & Precision \% & Recall \% \\
    \hline
    \textit{ Back To The Future III } &  83.19 &  55.52\\
    \textit{ Breach } &  92.78 &  51.37\\
    \textit{ Broken Flowers } &  92.03 &  4.41\\
    \textit{ Contagion } &  95.98 &  69.09\\
    \textit{ Dazed And Confused } &  80.48 &  11.96\\
    \textit{ Death Proof } &  93.13 &  49.76\\
    \textit{ Dinner For Schmucks } &  73.45 &  23.30\\
    \textit{ Escape From Alcatraz } &  95.16 &  47.91\\
    \textit{ Gosford Park } &  95.27 &  1.94\\
    \textit{ Salt } &  85.42 &  57.66\\
    \textit{ Super 8 } &  84.35 &  49.74\\
    \textbf{ Average } &  \textbf{89.39} &  \textbf{38.63}\\
    \label{tab:shotdetResults}
  \end{tabular}}
\end{center}


\subsection*{Feature-based approach}

\textbf{Features:} We consider four main types of features to detect cuts in videos. First, we consider changes in luminance (Lum), or mean value of a greyscale image, and color histograms (ColHist) between pairs of frames. Intuitively, luminace and color histograms should change gradually within a shot (low difference values) and drastically across a shot boundary. We also consider the magitude histogram of the optical flow (OptMag) between neighboring frames, and the changes in optical flow between neighboring pairs of frames (OptChange). We consider the absolute magnitude (OptMag), because the optical flow algorithm often produces large vectors when it does not find good matches between neighboring frames. We consider the changes (OptChange) because the optical flow should change less within a shot than it changes between neighboring shots.
\\

\begin{table}[h!]
  \begin{center}
  	\small{
	\begin{tabular}{l|lll}
	Feature   & Precision  & Recall     & F-Measure  \\ \hline
	Lum       & $0.62$ & $0.77$ & $0.69 $ \\
	ColHist   & $0.75$ & $0.78$ & $0.77$ \\
	OptMag    & $0.35$ & $0.82$ & $0.49$ \\
	OptChange & $0.22$ & $0.45$ & $0.30$ \\ \hline
	\end{tabular}
	}
  \end{center}
  \label{table:peakresults}
  \caption{This table shows results for predicting cuts in all videos in our dataset with the peak finding method with each feature (Lum, ColHist, OptMag, and OptChange).}
\end{table} 

\begin{table}[h!]
  \begin{center}
  	\small{
	\begin{tabular}{l|lll}
	Feature   & Precision  & Recall     & F-Measure  \\ \hline
	Lum       & 0.63      & 0.81   & 0.70      \\
	ColHist   & 0.84      & 0.77   & 0.80      \\
	OptMag    & 0.39      & 0.90   & 0.53      \\
	OptChange & 0.15      & 0.54   & 0.23      \\
	\textbf{SVM} & \textbf{0.94} & \textbf{0.84} & \textbf{0.89}\\ \hline
	\end{tabular}
	}
  \end{center}
  \label{table:allresults}
  \caption{This table shows results for predicting cuts in 3 test set videos with the peak finding method with each feature (Lum, ColHist, OptMag, and OptChange) and the SVM that combines the other predictions.}
\end{table} 


\noindent \textbf{Peak finding:} We use each feature to classify cuts by finding peaks in the feature signals. A peak is a local maximum that is at least some threshold higher than the points around it. We include precision, recall and f-measure averaged over all videos for the first 10000 frames in each video in Table~\ref{table:peakresults}.\\

\noindent \textbf{SVM results:} Independently, the color histograms and luminance features scored the best precision and recall. However each feature produced different detections, so we use an SVM to predict whether or not each frame is a cut, given whether or not a peak was predicted for each feature. We randomly selected a training set of 7 videos, and tested on the remaining three videos. Using this method we detect cuts with 0.94 precision , 0.84 recall, 0.89 f-measure. We compare this result to using the peak results alone on the three test videos in Table~\ref{allresults}. 

In the future, we will enter in the difference between the peak and the surrounding frames rather than a binary detect or not detect, as this could further aid the SVM technique.

\subsection*{CNN}

We designed a Convolutional Neural Network for use with shot boundary detection. We computed pairwise differences in luminance; vertical \& horizontal optical flow; \& the red, green, \& blue color channels for every pair of adjacent frames in a video. These differences were passed as as $6 \times h \times w$ matrix where $h = height$ \& $w = width$ of the frames. These arrays were then non-uniformly scaled to $256 \times 256$ pixels to ensure consistency across videos with different aspect ratios. 

Once the $N \times 6 \times 256 \times 256$ arrays had been constructed, they were passed into a 7 layer network, with a network architecture heavily inspired by LeNet \cite{lecun1998gradient}.

Due to time, data, and implementation limitations, we were unable to obtain results from using our architecture, however we plan to continue this work in future research. 


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "finalpaper"
%%% End:
