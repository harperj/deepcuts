{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get all shot annotation csvs\n",
    "#get the files\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join, basename, splitext\n",
    "CSV_PATH = \"/Users/alexhall/Documents/\" + \\\n",
    "       \"Coursework/computerVision/finalProject/shot_annot/csv/\"\n",
    "files = [f for f in listdir(CSV_PATH) if isfile(join(CSV_PATH, f)) and f[0] != '.']\n",
    "\n",
    "#Debug check: did the files load?\n",
    "#len(files)\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class to hold information from the csv\n",
    "class ShotAnnotation:\n",
    "    def __init__(self, mov, style, pre_frame, post_frame):\n",
    "        self.mov = mov\n",
    "        self.style = style\n",
    "        self.pre_frame = pre_frame\n",
    "        self.post_frame = post_frame\n",
    "                \n",
    "    def __repr__(self):\n",
    "        return \"PatternLocation()\"\n",
    "        \n",
    "    def __str__(self):\n",
    "        string = ''\n",
    "        buffer = ',  '\n",
    "        for v in vars(self):\n",
    "            string += v + ':' + getattr(self, v) + buffer\n",
    "        return str(string[:-len(buffer)])\n",
    "    \n",
    "#debug tests\n",
    "#test_annot = ShotAnnotation('movie', 'CUT', '10', '15')\n",
    "#print(test_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read shot_annot csv files\n",
    "\n",
    "# Dictionary of all movies\n",
    "# Each movie will have a list of ShotAnnotations\n",
    "# read the files into dictionary\n",
    "import csv\n",
    "annotations = {}\n",
    "annot_arrays = {}\n",
    "colNames = ['style', 'pre_frame', 'post_frame']\n",
    "\n",
    "for f in files:\n",
    "    full_path = CSV_PATH + f\n",
    "    name = (basename(f)).split('.')[0] #get only movie title\n",
    "    annotations[name] = []\n",
    "    annot_arrays[name] = {}\n",
    "    with open(CSV_PATH + f, 'rt') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        next(reader)    \n",
    "        idx = 0\n",
    "        for row in reader:\n",
    "            new_annot = ShotAnnotation(f, row[0], row[1], row[2])\n",
    "            annotations[name].append(new_annot)\n",
    "            for idx in range(int(row[1]), int(row[2]) + 1):\n",
    "                annot_arrays[name][idx] = 1\n",
    "            \n",
    "#Debug check: did the dictionary populate as expected?        \n",
    "#print(annot_arrays['anni005'])\n",
    "#print(type(dictionary['brokenFlowers']))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all signal files for movie in directory\n",
    "def get_frames(directory, signal_name):\n",
    "    path = directory + '/' + signal_name\n",
    "    dir_files = [f for f in listdir(path) if isfile(join(path, f)) and f[0] != '.']\n",
    "    return dir_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build dictionary of all frame lists\n",
    "def get_all_frames(directories, signal_name, path):\n",
    "    all_frames = {}\n",
    "    for d in directories:\n",
    "        all_frames[d] = get_frames(path + d, signal_name)\n",
    "        \n",
    "    return all_frames\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a dictionary with classifications per filename\n",
    "def get_classifications(directory, frames, signal, path):\n",
    "    class_dict = {}\n",
    "    for f in frames:\n",
    "        key = path + signal + '/' + directory + '/' + f\n",
    "        f_name = basename(f).split('.')[0]\n",
    "        val = annot_arrays[directory].get(int(f_name), 0)\n",
    "        class_dict[key] = val\n",
    "        return class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build dictionary of all movies and their frame classifications\n",
    "def get_all_classifications(directories, frames, signal, path):\n",
    "    classifications = {}\n",
    "    for d in directories:\n",
    "        val = get_classifications(d, frames[d], signal, path)\n",
    "        classifications[d] = val\n",
    "        \n",
    "    return classifications\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anni005': {'/Users/alexhall/Documents/Coursework/computerVision/finalProject/deepcuts/signals/sample_signal/anni005/000001.jpg': 0}}\n"
     ]
    }
   ],
   "source": [
    "#read signal directory\n",
    "#for each movie, build a dictionary frame_num:is_shot\n",
    "#use directory contents to get frame nums\n",
    "#reference shotness from csv files. \n",
    "#add black 'end frame' to each movie\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, basename, splitext\n",
    "path = \"/Users/alexhall/Documents/\" + \\\n",
    "       \"Coursework/computerVision/finalProject/deepcuts/signals/\"\n",
    "directories = [d for d in listdir(path) if isdir(join(path, d)) and d[0] != '.']\n",
    "\n",
    "#Debug check: did the files load?\n",
    "#len(files)\n",
    "#print(directories[0])\n",
    "test = get_all_frames(directories, 'sample_signal', path)\n",
    "#print(test)\n",
    "all_classes = get_all_classifications(directories, test, 'sample_signal', path)\n",
    "#print(test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write a text file with the following format\n",
    "#../relative/path_to/directory/file.jpg CLASS_NUMBER\n",
    "\n",
    "DATA_PATH = '/Users/alexhall/Documents/Coursework/computerVision/finalProject'\n",
    "full_path = DATA_PATH + '/' + 'data_1.txt'\n",
    "with open(full_path, mode='w', encoding = 'utf-8') as a_file:\n",
    "    for mov in all_classes:\n",
    "        for file in classes[mov]:\n",
    "            a_file.write(file + ' ' + str(classes[mov][file]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copy file created before\n",
    "#delete first line\n",
    "\n",
    "#TODO: add additional black 'end frame' reference to maintain parity\n",
    "\n",
    "my_file = open(full_path)\n",
    "lines = my_file.readlines()[1:]\n",
    "full_path_2 = DATA_PATH + '/' + 'data_2.txt'\n",
    "\n",
    "with open(full_path_2, mode='w', encoding = 'utf-8') as output:\n",
    "    for item in lines:\n",
    "        output.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "#import my_pycaffe as mp\n",
    "#import caffe\n",
    "import pdb\n",
    "import os\n",
    "#import lmdb\n",
    "import shutil\n",
    "import scipy.misc as scm\n",
    "import scipy.io as sio\n",
    "import copy\n",
    "\n",
    "def ims2hdf5(out_path, im, labels, batchSz, batchPath,\n",
    "             isColor=True, batchStNum=1,\n",
    "             isUInt8=True, scale=None,\n",
    "             newLabels=False):\n",
    "    '''\n",
    "        Converts an image dataset into hdf5\n",
    "    '''\n",
    "    h5SrcFile = os.path.join(batchPath, 'h5source.txt')\n",
    "    strFid    = open(h5SrcFile, 'w+')\n",
    "\n",
    "    dType = im.dtype\n",
    "    if isUInt8:\n",
    "        assert im.dtype==np.uint8, 'Images should be in uint8'\n",
    "        h5DType = 'u1'\n",
    "    else:\n",
    "        assert im.dtype==np.float32, 'Images can either be uint8 or float32'\t\t\n",
    "        h5DType = 'f'\n",
    "\n",
    "    if scale is not None:\n",
    "        im = im * scale\n",
    "        \n",
    "    N,ch,h,w = im.shape    \n",
    "    '''\n",
    "    #We should adjust this depending on the number of signals we expect. \n",
    "        if isColor:\n",
    "            assert im.ndim ==4 \n",
    "            N,ch,h,w = im.shape\n",
    "            assert ch==3, 'Color images must have 3 channels'\n",
    "        else:\n",
    "            assert im.ndim ==3\n",
    "            N,h,w    = im.shape\n",
    "            im       = np.reshape(im,(N,1,h,w))\n",
    "            ch       = 1\n",
    "    '''\n",
    "    count = batchStNum\n",
    "    for i in range(0,N,batchSz):\n",
    "        st      = i\n",
    "        en      = min(N, st + batchSz)\n",
    "        if st + batchSz > N:\n",
    "            break\n",
    "        h5File    = os.path.join(batchPath, 'batch%d.h5' % count)\n",
    "        h5Fid     = h5.File(h5File, 'w')\n",
    "        imBatch = np.zeros((N, ch, h, w), dType) \n",
    "        imH5      = h5Fid.create_dataset(out_path + '/data',(batchSz, ch, h, w), dtype=h5DType)\n",
    "        imH5[0:batchSz] = im[st:en]\n",
    "        if newLabels:\n",
    "            lbH5 = h5Fid.create_dataset(out_path + '/label', (batchSz,), dtype='f')\n",
    "            lbH5[0:batchSz] = labels[st:en].reshape((batchSz,))\n",
    "        else: \n",
    "            lbH5 = h5Fid.create_dataset(out_path + '/label', (batchSz,1,1,1), dtype='f')\n",
    "            lbH5[0:batchSz] = labels[st:en].reshape((batchSz,1,1,1))\n",
    "        h5Fid.close()\n",
    "        strFid.write('%s \\n' % h5File)\n",
    "        count += 1\t\n",
    "    strFid.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to grayscale, mimics the matlab function\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexhall/Documents/Coursework/computerVision/finalProject/deepcuts/signals/sample_signal/anni005/000001.jpg\n",
      "['000001.jpg']\n",
      "0\n",
      "(524, 475, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor mov in directories:\\nfor mov in all_classes:\\n    for file in classes[mov]:\\n        def ims2hdf5(im, labels, batchSz, \\n                     batchPath, isColor=True, \\n                     batchStNum=1, isUInt8=True,\\n                     scale=None, newLabels=False):\\n'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import misc\n",
    "\n",
    "\n",
    "\n",
    "DATA_PATH = '/Users/alexhall/Documents/Coursework/computerVision/' +\\\n",
    "            'finalProject/deepcuts/signals'\n",
    "full_path = DATA_PATH + '/' + 'data_1.txt'\n",
    "\n",
    "BATCH_PATH = '/Users/alexhall/Documents/Coursework/computerVision/' +\\\n",
    "            'finalProject/deepcuts/data_sets/batches'\n",
    "\n",
    "signal_types = [('sample_signal',False)]\n",
    "\n",
    "signal_frames = {}\n",
    "for d in directories:\n",
    "    class_labels = all_classes[d]\n",
    "    for sig_type in signal_types:\n",
    "        signal_frames[sig_type[0]] = get_frames(DATA_PATH +'/' + d, sig_type[0])\n",
    "    for frame in class_labels:\n",
    "        ims = None\n",
    "        labels = np.zeros([1,1])\n",
    "        #print(class_labels[frame])\n",
    "         \n",
    "        for sig, to_gray in signal_types:\n",
    "            print(frame)\n",
    "            print(signal_frames[sig])\n",
    "            frame_id = int((basename(frame)).split('.')[0]) - 1\n",
    "            print(frame_id)\n",
    "            im_file = signal_frames[sig][frame_id]\n",
    "            cur_im_path = DATA_PATH + '/' + d + '/' + sig + '/' + im_file            \n",
    "            this_im = misc.imread(cur_im_path)\n",
    "            \n",
    "            #convert to only a single 'color' channel. \n",
    "            if to_gray:\n",
    "                this_im = rgb2gray(this_im)\n",
    "                \n",
    "            if ims == None:\n",
    "                ims = this_im\n",
    "                labels[0] = class_labels[frame]\n",
    "            else:\n",
    "                ims = np.dstack((ims, this_im))\n",
    "            print(this_im.shape)\n",
    "        \n",
    "        #ims2hdf5 expects the data to be shaped as follows:\n",
    "        #Num_Images, channels, height, width\n",
    "        h,w,ch = ims.shape\n",
    "        ims = np.reshape(ims,(1,ch,h,w))\n",
    "\n",
    "        out_path = '/Users/alexhall/Documents/Coursework/computerVision/' +\\\n",
    "            'finalProject/deepcuts/datasets'\n",
    "        ims2hdf5(out_path, ims, labels, len(ims),BATCH_PATH, isColor = False) \n",
    "        \n",
    "'''\n",
    "for mov in directories:\n",
    "for mov in all_classes:\n",
    "    for file in classes[mov]:\n",
    "        def ims2hdf5(im, labels, batchSz, \n",
    "                     batchPath, isColor=True, \n",
    "                     batchStNum=1, isUInt8=True,\n",
    "                     scale=None, newLabels=False):\n",
    "'''            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
