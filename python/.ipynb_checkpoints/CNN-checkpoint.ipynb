{
 "metadata": {
  "name": "",
  "signature": "sha256:0c470b2bdc6fa7499906e429093de5995ee05f77317eb1ffc91497c6e47a403c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Deepcuts CNN"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a fully self-contained CNN Architecture for shot boundary detection. The code performs the following tasks:\n",
      "\n",
      "- Create a FrameDataSet class inheriting 'DenseDesignMatrix' to hold the data. The Pylearn2 CNN architecture expects a DenseDesignMatrix container.\n",
      "\n",
      "- Read all data files\n",
      "\n",
      "- Create an ndarray, frame_pair, of dimension Channel x Height x Width for the data of each frame-pair in both the train & test set. The format of the array is as follows:\n",
      "    - Channel = The signal type (e.g. horizontal flow)\n",
      "    - Height = The height of the image \n",
      "    - Width = The Width of the images\n",
      "\n",
      "- Put all of the frame_pairs into a FrameDataSet\n",
      "\n",
      "- Define the network architecture using the YAML markup language\n",
      "\n",
      "- Run the CNN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dependencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/pylearn2/> Pylearn2</a>\n",
      "\n",
      "- <a href=http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux/#axzz3ZD4QUCPt> CUDA (optional)</a>\n",
      "    - <a href=http://www.quantstart.com/articles/Installing-Nvidia-CUDA-on-Ubuntu-14-04-for-Linux-GPU-Computing> A helpful CUDA install guide </a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/theano/tutorial/using_gpu.html> Theano GPU Settings </a> (if using cuda)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References & Helpful Links"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/pylearn2/tutorial/index.html#tutorial> Python Quick Start Tutorial </a>\n",
      "- <a href=http://deeplearning.net/software/pylearn2/yaml_tutorial/index.html#yaml-tutorial> YAML for Pylearn2</a>\n",
      "- <a href=http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/convolutional_network/convolutional_network.ipynb>iPython Notebook CNN Tutorial</a>\n",
      "- <a href=http://nbviewer.ipython.org/gist/cancan101/ea563e394ea968127e0e > Fully Contained iPython Notebook CNN </a>\n",
      "- <a href=https://github.com/kastnerkyle/kaggle-cifar10/blob/master/kaggle_dataset.py> Sample Dataset Class </a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Put all of the imports here\n",
      "#NOTE: Importing all of pylearn2 is VERY slow. \n",
      "# - Import only the needed components.\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "import numpy as np\n",
      "from scipy import misc\n",
      "\n",
      "import theano\n",
      "\n",
      "from theano.compat.six.moves import xrange\n",
      "from pylearn2.datasets import dense_design_matrix\n",
      "from pylearn2.datasets import control\n",
      "from pylearn2.datasets import cache\n",
      "from pylearn2.utils import serial\n",
      "from pylearn2.utils.rng import make_np_rng\n",
      "\n",
      "from os import listdir\n",
      "from os.path import isfile, isdir, join, basename, splitext\n",
      "\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import sys\n",
      "import Image\n",
      "\n",
      "import csv\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Check which device theano uses (gpu or cpu\n",
      "print theano.config.device"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cpu\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Define Global Parameters\n",
      "TRAIN_DATA = '/home/alex/Desktop/deepcuts_data/signals/'\n",
      "TEST_DATA = '/home/alex/Desktop/deepcuts_data/signals/'\n",
      "TRAIN_LABELS = \"/home/alex/Desktop/deepcuts_data/shot_annot/csv/\"\n",
      "TEST_LABELS = \"/home/alex/Desktop/deepcuts_data/shot_annot/csv/\"\n",
      "\n",
      "\n",
      "FORCED_HEIGHT = 512\n",
      "FORCED_WIDTH = 512\n",
      "\n",
      "BATCH_COUNT = sys.maxsize\n",
      "\n",
      "SIGNALS = ['sample_signal']\n",
      "SIG_COUNT = 3\n",
      "\n",
      "#Signals that should be converted to single channel\n",
      "NEEDS_COLOR_CONVERSION = ['h_flow', 'v_flow', 'luminance'] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9223372036854775807\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Each pixel value is the average from rgb\n",
      "#This is for mathematical accuracy\n",
      "#This is NOT for producing visually accurate rgb2gray conversion\n",
      "def convert(signal_type, im):\n",
      "    \n",
      "    im = im.resize((FORCED_HEIGHT, FORCED_WIDTH))\n",
      "    image = np.asarray(im)\n",
      "    \n",
      "    h,w,ch = image.shape\n",
      "    assert (ch < h and ch < w), 'Invalid Input Size: Expected data input is of size H x W x Ch'\n",
      "    \n",
      "    if signal_type in NEEDS_COLOR_CONVERSION:\n",
      "        output = np.zeros([h,w])\n",
      "        for i in range(0, ch):\n",
      "            output = output + image[:,:,i]\n",
      "        \n",
      "        image = output / ch        \n",
      "    #After color conversion, we reshape for CNN input. \n",
      "    #CNN Expects ndarry to be N x Channel x Height x Width\n",
      "    \n",
      "    #move channels to front axis\n",
      "    image = image.swapaxes(0,2) #Now image is Ch x W x H\n",
      "    \n",
      "    #swap W and H\n",
      "    image = image.swapaxes(1,2) #Now image is Ch x H x W\n",
      "    \n",
      "    return image\n",
      "    \n",
      "            \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get all files in directory\n",
      "def get_all_files(path):\n",
      "    files = [f for f in listdir(path) if isfile(join(path, f)) and \\\n",
      "             f[0] != '.' ] #ignore hidden files\n",
      "    return sorted(files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get all subdirectories in a directory\n",
      "def get_all_dirs(path):\n",
      "    folders = [f for f in listdir(path) if isdir(join(path, f)) and \\\n",
      "               f[0] != '.'] #ignore hiddin directories\n",
      "    return sorted(folders)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get all signal files for movie in directory\n",
      "def get_images(movie, signal, data_path):\n",
      "    path = data_path + movie + '/' + signal + '/'\n",
      "    files = get_all_files(path)\n",
      "    image_dict = {}\n",
      "    \n",
      "    for f in files:\n",
      "        im = Image.open(path + f)\n",
      "        im.load()\n",
      "        image_dict[int(f[:-4])] = convert(signal, im)\n",
      "        \n",
      "    return image_dict\n",
      "\n",
      "#get_images('anni005', 'sample_signal')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_movie_signals(movie, data_path):\n",
      "    mov_sigs = {}\n",
      "    for s in SIGNALS:\n",
      "        mov_sigs[s] = get_images(movie, s, data_path)\n",
      "        \n",
      "    #now vstack them. \n",
      "    mov_compiled = mov_sigs[SIGNALS[0]]\n",
      "    \n",
      "    for f in mov_compiled:\n",
      "        for s in SIGNALS[1:]:\n",
      "            mov_compiled[f] =  np.vstack(mov_compiled[f], mov_sigs[s])\n",
      "            \n",
      "    return mov_compiled\n",
      "    \n",
      "    \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_all_sigs(data_path):\n",
      "    dirs = get_all_dirs(data_path)\n",
      "    print('Found ' + str(len(dirs)) + ' movies: ')\n",
      "    print(dirs)\n",
      "    all_sigs = {}\n",
      "    for d in dirs:\n",
      "        all_sigs[d] = get_movie_signals(d, data_path)\n",
      "    \n",
      "    return all_sigs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Read shot_annot csv files\n",
      "\n",
      "# Dictionary of all movies\n",
      "# Each movie will have a list of ShotAnnotations\n",
      "# read the files into dictionary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def get_labels(label_path):\n",
      "    \n",
      "    files = [f for f in listdir(label_path) if isfile(join(label_path, f)) and f[0] != '.']\n",
      "    annotations = {}\n",
      "    annot_arrays = {}\n",
      "    colNames = ['style', 'pre_frame', 'post_frame']\n",
      "    \n",
      "    for f in files:\n",
      "        full_path = label_path + f\n",
      "        name = (basename(f)).split('.')[0] #get only movie title\n",
      "        annotations[name] = []\n",
      "        annot_arrays[name] = {}\n",
      "        with open(label_path + f, 'rt') as csvfile:\n",
      "            reader = csv.reader(csvfile, delimiter=',')\n",
      "            next(reader)    \n",
      "            idx = 0\n",
      "            for row in reader:\n",
      "                #new_annot = ShotAnnotation(f, row[0], row[1], row[2])\n",
      "                #annotations[name].append(new_annot)\n",
      "                if(row[0] == 'CUT'):\n",
      "                    annot_arrays[name][row[1]] = 1\n",
      "\n",
      "    #Debug check: did the dictionary populate as expected?        \n",
      "    print('Gathered labels for ',len(annot_arrays), 'videos')\n",
      "    return annot_arrays\n",
      "    \n",
      "    \n",
      "#get_labels()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Make the final image and label arrays\n",
      "\n",
      "def prep_data(data_path, label_path):\n",
      "    signals = get_all_sigs(data_path)\n",
      "    labels = get_labels(label_path)\n",
      "    \n",
      "    final_labels = []\n",
      "    signal_ndArrays = np.empty((1, SIG_COUNT, FORCED_HEIGHT, FORCED_WIDTH))\n",
      "    for m in sorted(signals):\n",
      "        max_val = max([int(k) for k in signals[m]])\n",
      "        \n",
      "        these_labels = [0] * (max_val - 1)\n",
      "        for cut in labels[m]:\n",
      "            #-1 because frames are indexed starting at 1\n",
      "            #these_labels[int(cut) - 1] = labels[cut]\n",
      "            x = 1\n",
      "        final_labels.append(these_labels)\n",
      "        itermov = iter(sorted(signals[m]))\n",
      "        \n",
      "        if(len(signal_ndArrays) == 1):\n",
      "            signal_ndArrays[0,:,:,:] = signals[m][1]\n",
      "            next(itermov)\n",
      "            \n",
      "        for sig in itermov:\n",
      "            new_array = np.empty((1, SIG_COUNT, FORCED_HEIGHT, FORCED_WIDTH))\n",
      "            new_array[0,:,:,:] = signals[m][sig]\n",
      "            signal_ndArrays = np.vstack((signal_ndArrays, new_array))\n",
      "            \n",
      "    print final_labels\n",
      "    print(signal_ndArrays.shape)\n",
      "    \n",
      "    return{'labels':final_labels, 'signals':signal_ndArrays}\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create the FrameDataSet Class\n",
      "class FrameDataSet(dense_design_matrix.DenseDesignMatrix):\n",
      "    \n",
      "    def __init__(self, data_path, label_path):\n",
      "        data = prep_data(data_path, label_path)\n",
      "        labels = data['labels']\n",
      "        ims = data['signals']\n",
      "        \n",
      "        self.num_ims, self.ch, self.h, self.w = ims.shape\n",
      "        self.img_shape = (self.ch, self.h, self.w)\n",
      "        start_idx = 0\n",
      "        self.max_count = sys.maxsize\n",
      "        self.label_names = [0, 1]\n",
      "        self.n_classes = len(self.label_names)    \n",
      "            \n",
      "            \n",
      "        #The following parts might not be necessary.\n",
      "        self.one_hot = False\n",
      "        self.gcn = 55. #Don't know what this does.\n",
      "        \n",
      "    \n",
      "        def get_labels():\n",
      "            return labels\n",
      "        \n",
      "        self.label_map = {k: v for k, v in zip(self.label_names,\\\n",
      "                                               range(self.n_classes))}\n",
      "        self.label_unmap = {v: k for k, v in zip(self.label_names,\\\n",
      "                                               range(self.n_classes))}\n",
      "        \n",
      "        \n",
      "        \n",
      "                                         \n",
      "            \n",
      "    \n",
      "            \n",
      "        \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all_data = FrameDataSet(TRAIN_DATA, TRAIN_LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python\n",
      "from pylearn2.models import mlp, maxout\n",
      "from pylearn2.costs.mlp.dropout import Dropout\n",
      "from pylearn2.training_algorithms import sgd, learning_rule\n",
      "from pylearn2.termination_criteria import EpochCounter\n",
      "from pylearn2.datasets.preprocessing import Pipeline, ZCA\n",
      "from pylearn2.datasets.preprocessing import GlobalContrastNormalization\n",
      "from pylearn2.space import Conv2DSpace\n",
      "from pylearn2.train import Train\n",
      "from pylearn2.train_extensions import best_params, window_flip\n",
      "from pylearn2.utils import serial\n",
      "\n",
      "#Define Datasets here\n",
      "trn = FrameDataSet(TRAIN_DATA, TRAIN_LABELS)\n",
      "\n",
      "tst = FrameDataSet(TEST_DATA, TEST_LABELS)\n",
      "\n",
      "\n",
      "#Define the network here\n",
      "in_space = Conv2DSpace(shape=(32, 32),\n",
      "                       num_channels=3,\n",
      "                       axes=('c', 0, 1, 'b'))\n",
      "\n",
      "l1 = mlp.ConvRectifiedLinear(layer_name = 'h2',\n",
      "                     output_channels=64 ,\n",
      "                     irange= .05,\n",
      "                     kernel_shape= (5, 5),\n",
      "                     pool_shape= (4, 4),\n",
      "                     pool_stride= (2, 2),\n",
      "                     max_kernel_norm= 1.9365)\n",
      "\n",
      "l2 = mlp.ConvRectifiedLinear(layer_name='l2',\n",
      "                           pad=3,\n",
      "                           tied_b=1,\n",
      "                           W_lr_scale=.05,\n",
      "                           b_lr_scale=.05,\n",
      "                           num_channels=192,\n",
      "                           num_pieces=2,\n",
      "                           kernel_shape=(8, 8),\n",
      "                           pool_shape=(4, 4),\n",
      "                           pool_stride=(2, 2),\n",
      "                           irange=.005,\n",
      "                           max_kernel_norm=1.9365,\n",
      "                           partial_sum=15)\n",
      "\n",
      "l3 = mlp.ConvRectifiedLinear(layer_name='l3',\n",
      "                           pad=3,\n",
      "                           tied_b=1,\n",
      "                           W_lr_scale=.05,\n",
      "                           b_lr_scale=.05,\n",
      "                           num_channels=192,\n",
      "                           num_pieces=2,\n",
      "                           kernel_shape=(5, 5),\n",
      "                           pool_shape=(2, 2),\n",
      "                           pool_stride=(2, 2),\n",
      "                           irange=.005,\n",
      "                           max_kernel_norm=1.9365)\n",
      "\n",
      "l4 = mlp.ConvRectifiedLinear(layer_name='l4',\n",
      "                   irange=.005,\n",
      "                   num_units=500,\n",
      "                   num_pieces=5,\n",
      "                   max_col_norm=1.9)\n",
      "\n",
      "output = mlp.Softmax(layer_name='y',\n",
      "                     n_classes=10,\n",
      "                     irange=.005,\n",
      "                     max_col_norm=1.9365)\n",
      "\n",
      "layers = [l1, l2, l3, l4, output]\n",
      "\n",
      "#Define the model\n",
      "#Not sure if we need to modify this.\n",
      "mdl = mlp.MLP(layers,\n",
      "              input_space=in_space)\n",
      "\n",
      "\n",
      "#Not sure what this does from here to next comment.\n",
      "trainer = sgd.SGD(learning_rate=.17,\n",
      "                  batch_size=128,\n",
      "                  learning_rule=learning_rule.Momentum(.5),\n",
      "                  # Remember, default dropout is .5\n",
      "                  cost=Dropout(input_include_probs={'l1': .8},\n",
      "                               input_scales={'l1': 1.}),\n",
      "                  termination_criterion=EpochCounter(max_epochs=475),\n",
      "                  monitoring_dataset={'valid': tst,\n",
      "                                      'train': trn})\n",
      "\n",
      "preprocessor = Pipeline([GlobalContrastNormalization(scale=55.), ZCA()])\n",
      "trn.apply_preprocessor(preprocessor=preprocessor, can_fit=True)\n",
      "tst.apply_preprocessor(preprocessor=preprocessor, can_fit=False)\n",
      "serial.save('deepcuts_preprocessor.pkl', preprocessor)\n",
      "\n",
      "watcher = best_params.MonitorBasedSaveBest(\n",
      "    channel_name='valid_y_misclass',\n",
      "    save_path='deepcuts_maxout_zca.pkl')\n",
      "\n",
      "velocity = learning_rule.MomentumAdjustor(final_momentum=.65,\n",
      "                                          start=1,\n",
      "                                          saturate=250)\n",
      "\n",
      "decay = sgd.LinearDecayOverEpoch(start=1,\n",
      "                                 saturate=500,\n",
      "                                 decay_factor=.01)\n",
      "\n",
      "win = window_flip.WindowAndFlipC01B(pad_randomized=8,\n",
      "                                    window_shape=(32, 32),\n",
      "                                    randomize=[trn],\n",
      "                                    center=[tst])\n",
      "\n",
      "#Define experiment\n",
      "experiment = Train(dataset=trn,\n",
      "                   model=mdl,\n",
      "                   algorithm=trainer,\n",
      "                   extensions=[watcher, velocity, decay, win])\n",
      "\n",
      "#Run experiment\n",
      "experiment.main_loop()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-33-8040979324cb>, line 24)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-8040979324cb>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    l1 = mlp.ConvRectifiedLinear(layer_name 'h2',\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yaml = \"\"\"!obj:pylearn2.train.Train {\n",
      "    dataset: &train !obj:FrameDataSet {\n",
      "        data_path: '\"\"\" + TRAIN_DATA + \"\"\"',\n",
      "        label_path: '\"\"\" + TRAIN_LABELS + \"\"\"',\n",
      "    },\n",
      "    model: !obj:pylearn2.models.mlp.MLP {\n",
      "        batch_size: \"\"\" + str(BATCH_COUNT) + \"\"\" i,\n",
      "        input_space: !obj:pylearn2.space.Conv2DSpace {\n",
      "            shape: [28, 28],\n",
      "            num_channels: 1\n",
      "        },\n",
      "        layers: [ !obj:pylearn2.models.mlp.ConvRectifiedLinear {\n",
      "                     layer_name: 'h2',\n",
      "                     output_channels: %(output_channels_h2)i,\n",
      "                     irange: .05,\n",
      "                     kernel_shape: [5, 5],\n",
      "                     pool_shape: [4, 4],\n",
      "                     pool_stride: [2, 2],\n",
      "                     max_kernel_norm: 1.9365\n",
      "                 }, !obj:pylearn2.models.mlp.ConvRectifiedLinear {\n",
      "                     layer_name: 'h3',\n",
      "                     output_channels: %(output_channels_h3)i,\n",
      "                     irange: .05,\n",
      "                     kernel_shape: [5, 5],\n",
      "                     pool_shape: [4, 4],\n",
      "                     pool_stride: [2, 2],\n",
      "                     max_kernel_norm: 1.9365\n",
      "                 }, !obj:pylearn2.models.mlp.Softmax {\n",
      "                     max_col_norm: 1.9365,\n",
      "                     layer_name: 'y',\n",
      "                     n_classes: 10,\n",
      "                     istdev: .05\n",
      "                 }\n",
      "                ],\n",
      "    },\n",
      "    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n",
      "        batch_size: %(batch_size)i,\n",
      "        learning_rate: .01,\n",
      "        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {\n",
      "            init_momentum: .5\n",
      "        },\n",
      "        monitoring_dataset:\n",
      "            {\n",
      "                'valid' : !obj:pylearn2.datasets.mnist.MNIST {\n",
      "                              which_set: 'train',\n",
      "                              start: 50000,\n",
      "                              stop:  %(valid_stop)i\n",
      "                          },\n",
      "                'test'  : !obj:pylearn2.datasets.mnist.MNIST {\n",
      "                              which_set: 'test',\n",
      "                              stop: %(test_stop)i\n",
      "                          }\n",
      "            },\n",
      "        cost: !obj:pylearn2.costs.cost.SumOfCosts { costs: [\n",
      "            !obj:pylearn2.costs.cost.MethodCost {\n",
      "                method: 'cost_from_X'\n",
      "            }, !obj:pylearn2.costs.mlp.WeightDecay {\n",
      "                coeffs: [ .00005, .00005, .00005 ]\n",
      "            }\n",
      "            ]\n",
      "        },\n",
      "        termination_criterion: !obj:pylearn2.termination_criteria.And {\n",
      "            criteria: [\n",
      "                !obj:pylearn2.termination_criteria.MonitorBased {\n",
      "                    channel_name: \"valid_y_misclass\",\n",
      "                    prop_decrease: 0.50,\n",
      "                    N: 10\n",
      "                },\n",
      "                !obj:pylearn2.termination_criteria.EpochCounter {\n",
      "                    max_epochs: %(max_epochs)i\n",
      "                },\n",
      "            ]\n",
      "        },\n",
      "    },\n",
      "    extensions:\n",
      "        [ !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {\n",
      "             channel_name: 'valid_y_misclass',\n",
      "             save_path: \"%(save_path)s/convolutional_network_best.pkl\"\n",
      "        }, !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {\n",
      "            start: 1,\n",
      "            saturate: 10,\n",
      "            final_momentum: .99\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylearn2.config import yaml_parse\n",
      "train = yaml_parse.load(yaml)\n",
      "#train.main_loop()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ScannerError",
       "evalue": "while scanning for the next token\nfound character '%' that cannot start any token\n  in \"<string>\", line 14, column 39:\n     ...                output_channels: %(output_channels_h2)i,\n                                         ^",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mScannerError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-32-b6401480ffaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpylearn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml_parse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#train.main_loop()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/config/yaml_parse.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(stream, environ, instantiate, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mproxy_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_instantiate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/__init__.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_single_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/constructor.pyc\u001b[0m in \u001b[0;36mget_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_single_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Ensure that the stream contains a single document and construct it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_single_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mget_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStreamEndEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Ensure that the stream contains no more documents.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Compose the root node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Drop the DOCUMENT-END event.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m#            \"found duplicate key\", key_event.start_mark)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mitem_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;31m#node.value[item_key] = item_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m#            \"found duplicate key\", key_event.start_mark)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mitem_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;31m#node.value[item_key] = item_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_scalar_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequenceStartEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_sequence_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequenceEndEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mend_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m#            \"found duplicate key\", key_event.start_mark)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mitem_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;31m#node.value[item_key] = item_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/composer.pyc\u001b[0m in \u001b[0;36mcompose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompose_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAliasEvent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0manchor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/parser.pyc\u001b[0m in \u001b[0;36mcheck_event\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/parser.pyc\u001b[0m in \u001b[0;36mparse_flow_mapping_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueToken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlowEntryToken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlowMappingEndToken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_flow_mapping_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_flow_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/scanner.pyc\u001b[0m in \u001b[0;36mcheck_token\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Check if the next token is one of the given types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_more_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_more_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/yaml/scanner.pyc\u001b[0m in \u001b[0;36mfetch_more_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ScannerError(\"while scanning for the next token\", None,\n\u001b[1;32m    256\u001b[0m                 \u001b[0;34m\"found character %r that cannot start any token\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 % ch.encode('utf-8'), self.get_mark())\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# Simple keys treatment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mScannerError\u001b[0m: while scanning for the next token\nfound character '%' that cannot start any token\n  in \"<string>\", line 14, column 39:\n     ...                output_channels: %(output_channels_h2)i,\n                                         ^"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}