{
 "metadata": {
  "name": "",
  "signature": "sha256:85744cf7ffa86c50f0424b975914c5ffa0ed5becf0422b855557d29db315910a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Deepcuts CNN"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a fully self-contained CNN Architecture for shot boundary detection. The code performs the following tasks:\n",
      "\n",
      "- Create a FrameDataSet class inheriting 'DenseDesignMatrix' to hold the data. The Pylearn2 CNN architecture expects a DenseDesignMatrix container.\n",
      "\n",
      "- Read all data files\n",
      "\n",
      "- Create an ndarray, frame_pair, of dimension Channel x Height x Width for the data of each frame-pair in both the train & test set. The format of the array is as follows:\n",
      "    - Channel = The signal type (e.g. horizontal flow)\n",
      "    - Height = The height of the image \n",
      "    - Width = The Width of the images\n",
      "\n",
      "- Put all of the frame_pairs into a FrameDataSet\n",
      "\n",
      "- Define the network architecture using the YAML markup language\n",
      "\n",
      "- Run the CNN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dependencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/pylearn2/> Pylearn2</a>\n",
      "\n",
      "- <a href=http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux/#axzz3ZD4QUCPt> CUDA (optional)</a>\n",
      "    - <a href=http://www.quantstart.com/articles/Installing-Nvidia-CUDA-on-Ubuntu-14-04-for-Linux-GPU-Computing> A helpful CUDA install guide </a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/theano/tutorial/using_gpu.html> Theano GPU Settings </a> (if using cuda)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References & Helpful Links"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/pylearn2/tutorial/index.html#tutorial> Python Quick Start Tutorial </a>\n",
      "- <a href=http://deeplearning.net/software/pylearn2/yaml_tutorial/index.html#yaml-tutorial> YAML for Pylearn2</a>\n",
      "- <a href=http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/convolutional_network/convolutional_network.ipynb>iPython Notebook CNN Tutorial</a>\n",
      "- <a href=http://nbviewer.ipython.org/gist/cancan101/ea563e394ea968127e0e > Fully Contained iPython Notebook CNN </a>\n",
      "- <a href=https://github.com/kastnerkyle/kaggle-cifar10/blob/master/kaggle_dataset.py> Sample Dataset Class </a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Put all of the imports here\n",
      "#NOTE: Importing all of pylearn2 is VERY slow. \n",
      "# - Import only the needed components.\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "import numpy as np\n",
      "from scipy import misc\n",
      "\n",
      "import theano\n",
      "\n",
      "from theano.compat.six.moves import xrange\n",
      "from pylearn2.datasets import dense_design_matrix\n",
      "from pylearn2.datasets import control\n",
      "from pylearn2.datasets import cache\n",
      "from pylearn2.utils import serial\n",
      "from pylearn2.utils.rng import make_np_rng\n",
      "\n",
      "from os import listdir\n",
      "from os.path import isfile, isdir, join, basename, splitext\n",
      "\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import sys\n",
      "import Image\n",
      "\n",
      "import csv\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Check which device theano uses (gpu or cpu\n",
      "print theano.config.device"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cpu\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Define Global Parameters\n",
      "TRAIN_DATA = '/home/alex/Desktop/deepcuts_data/signals/'\n",
      "TEST_DATA = '/home/alex/Desktop/deepcuts_data/signals/'\n",
      "TRAIN_LABELS = \"/home/alex/Desktop/deepcuts_data/shot_annot/csv/\"\n",
      "TEST_LABELS = \"/home/alex/Desktop/deepcuts_data/shot_annot/csv/\"\n",
      "\n",
      "\n",
      "FORCED_HEIGHT = 32\n",
      "FORCED_WIDTH = 32\n",
      "\n",
      "BATCH_COUNT = 100\n",
      "\n",
      "SIGNALS = ['sample_signal']\n",
      "SIG_COUNT = 3\n",
      "\n",
      "#Signals that should be converted to single channel\n",
      "NEEDS_COLOR_CONVERSION = ['h_flow', 'v_flow', 'luminance'] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Each pixel value is the average from rgb\n",
      "#This is for mathematical accuracy\n",
      "#This is NOT for producing visually accurate rgb2gray conversion\n",
      "def convert(signal_type, im):\n",
      "    \n",
      "    im = im.resize((FORCED_HEIGHT, FORCED_WIDTH))\n",
      "    image = np.asarray(im)\n",
      "    \n",
      "    h,w,ch = image.shape\n",
      "    assert (ch < h and ch < w), 'Invalid Input Size: Expected data input is of size H x W x Ch'\n",
      "    \n",
      "    if signal_type in NEEDS_COLOR_CONVERSION:\n",
      "        output = np.zeros([h,w])\n",
      "        for i in range(0, ch):\n",
      "            output = output + image[:,:,i]\n",
      "        \n",
      "        image = output / ch        \n",
      "    #After color conversion, we reshape for CNN input. \n",
      "    #CNN Expects ndarry to be N x Channel x Height x Width\n",
      "    \n",
      "    #move channels to front axis\n",
      "    image = image.swapaxes(0,2) #Now image is Ch x W x H\n",
      "    \n",
      "    #swap W and H\n",
      "    image = image.swapaxes(1,2) #Now image is Ch x H x W\n",
      "    \n",
      "    return image\n",
      "    \n",
      "            \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get all files in directory\n",
      "def get_all_files(path):\n",
      "    files = [f for f in listdir(path) if isfile(join(path, f)) and \\\n",
      "             f[0] != '.' ] #ignore hidden files\n",
      "    return sorted(files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get all subdirectories in a directory\n",
      "def get_all_dirs(path):\n",
      "    folders = [f for f in listdir(path) if isdir(join(path, f)) and \\\n",
      "               f[0] != '.'] #ignore hiddin directories\n",
      "    return sorted(folders)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get all signal files for movie in directory\n",
      "def get_images(movie, signal, data_path):\n",
      "    path = data_path + movie + '/' + signal + '/'\n",
      "    files = get_all_files(path)\n",
      "    image_dict = {}\n",
      "    \n",
      "    for f in files:\n",
      "        im = Image.open(path + f)\n",
      "        im.load()\n",
      "        image_dict[int(f[:-4])] = convert(signal, im)\n",
      "        \n",
      "    return image_dict\n",
      "\n",
      "#get_images('anni005', 'sample_signal')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_movie_signals(movie, data_path):\n",
      "    mov_sigs = {}\n",
      "    for s in SIGNALS:\n",
      "        mov_sigs[s] = get_images(movie, s, data_path)\n",
      "        \n",
      "    #now vstack them. \n",
      "    mov_compiled = mov_sigs[SIGNALS[0]]\n",
      "    \n",
      "    for f in mov_compiled:\n",
      "        for s in SIGNALS[1:]:\n",
      "            mov_compiled[f] =  np.vstack(mov_compiled[f], mov_sigs[s])\n",
      "            \n",
      "    return mov_compiled\n",
      "    \n",
      "    \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_all_sigs(data_path):\n",
      "    dirs = get_all_dirs(data_path)\n",
      "    print('Found ' + str(len(dirs)) + ' movies: ')\n",
      "    print(dirs)\n",
      "    all_sigs = {}\n",
      "    for d in dirs:\n",
      "        all_sigs[d] = get_movie_signals(d, data_path)\n",
      "    \n",
      "    return all_sigs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Read shot_annot csv files\n",
      "\n",
      "# Dictionary of all movies\n",
      "# Each movie will have a list of ShotAnnotations\n",
      "# read the files into dictionary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def get_labels(label_path):\n",
      "    \n",
      "    files = [f for f in listdir(label_path) if isfile(join(label_path, f)) and f[0] != '.']\n",
      "    annotations = {}\n",
      "    annot_arrays = {}\n",
      "    colNames = ['style', 'pre_frame', 'post_frame']\n",
      "    \n",
      "    for f in files:\n",
      "        full_path = label_path + f\n",
      "        name = (basename(f)).split('.')[0] #get only movie title\n",
      "        annotations[name] = []\n",
      "        annot_arrays[name] = {}\n",
      "        with open(label_path + f, 'rt') as csvfile:\n",
      "            reader = csv.reader(csvfile, delimiter=',')\n",
      "            next(reader)    \n",
      "            idx = 0\n",
      "            for row in reader:\n",
      "                #new_annot = ShotAnnotation(f, row[0], row[1], row[2])\n",
      "                #annotations[name].append(new_annot)\n",
      "                if(row[0] == 'CUT'):\n",
      "                    annot_arrays[name][row[1]] = 1\n",
      "\n",
      "    #Debug check: did the dictionary populate as expected?        \n",
      "    print('Gathered labels for ',len(annot_arrays), 'videos')\n",
      "    return annot_arrays\n",
      "    \n",
      "    \n",
      "#get_labels()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Make the final image and label arrays\n",
      "\n",
      "def prep_data(data_path, label_path):\n",
      "    signals = get_all_sigs(data_path)\n",
      "    labels = get_labels(label_path)\n",
      "    \n",
      "    final_labels = []\n",
      "    signal_ndArrays = np.empty((1, SIG_COUNT, FORCED_HEIGHT, FORCED_WIDTH))\n",
      "    for m in sorted(signals):\n",
      "        max_val = max([int(k) for k in signals[m]])\n",
      "        \n",
      "        these_labels = [0] * (max_val - 1)\n",
      "        for cut in labels[m]:\n",
      "            #-1 because frames are indexed starting at 1\n",
      "            #these_labels[int(cut) - 1] = labels[cut]\n",
      "            x = 1\n",
      "        final_labels.append(these_labels)\n",
      "        itermov = iter(sorted(signals[m]))\n",
      "        \n",
      "        if(len(signal_ndArrays) == 1):\n",
      "            signal_ndArrays[0,:,:,:] = signals[m][1]\n",
      "            next(itermov)\n",
      "            \n",
      "        for sig in itermov:\n",
      "            new_array = np.empty((1, SIG_COUNT, FORCED_HEIGHT, FORCED_WIDTH))\n",
      "            new_array[0,:,:,:] = signals[m][sig]\n",
      "            signal_ndArrays = np.vstack((signal_ndArrays, new_array))\n",
      "            \n",
      "    print final_labels\n",
      "    print(signal_ndArrays.shape)\n",
      "    \n",
      "    return{'labels':final_labels, 'signals':signal_ndArrays}\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create the FrameDataSet Class\n",
      "class FrameDataSet(dense_design_matrix.DenseDesignMatrix):\n",
      "    \n",
      "    def __init__(self, data_path, label_path):\n",
      "        data = prep_data(data_path, label_path)\n",
      "        y = np.asarray(data['labels'])\n",
      "        print(y.size)\n",
      "        X = data['signals']\n",
      "        \n",
      "        self.num_ims, self.ch, self.h, self.w = X.shape\n",
      "        self.img_shape = (self.ch, self.h, self.w)\n",
      "        start_idx = 0\n",
      "        self.max_count = sys.maxsize\n",
      "        self.label_names = [0, 1]\n",
      "        self.n_classes = len(self.label_names)    \n",
      "            \n",
      "            \n",
      "        #The following parts might not be necessary.\n",
      "        self.one_hot = False\n",
      "        self.gcn = 55. #Don't know what this does.\n",
      "        \n",
      "    \n",
      "        def get_labels():\n",
      "            return labels\n",
      "        \n",
      "        self.label_map = {k: v for k, v in zip(self.label_names,\\\n",
      "                                               range(self.n_classes))}\n",
      "        self.label_unmap = {v: k for k, v in zip(self.label_names,\\\n",
      "                                               range(self.n_classes))}\n",
      "        \n",
      "        super(FrameDataSet, self).__init__(y=y,\n",
      "                                           topo_view=X)\n",
      "        \n",
      "        \n",
      "        \n",
      "                                         \n",
      "            \n",
      "    \n",
      "            \n",
      "        \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all_data = FrameDataSet(TRAIN_DATA, TRAIN_LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python\n",
      "from pylearn2.models import mlp\n",
      "from pylearn2.costs.mlp.dropout import Dropout\n",
      "from pylearn2.training_algorithms import sgd, learning_rule\n",
      "from pylearn2.termination_criteria import EpochCounter\n",
      "from pylearn2.datasets.preprocessing import Pipeline, ZCA\n",
      "from pylearn2.datasets.preprocessing import GlobalContrastNormalization\n",
      "from pylearn2.space import Conv2DSpace\n",
      "from pylearn2.train import Train\n",
      "from pylearn2.train_extensions import best_params, window_flip\n",
      "from pylearn2.utils import serial\n",
      "\n",
      "#Define Datasets here\n",
      "trn = FrameDataSet(TRAIN_DATA, TRAIN_LABELS)\n",
      "\n",
      "tst = FrameDataSet(TEST_DATA, TEST_LABELS)\n",
      "\n",
      "\n",
      "#Define the network here\n",
      "in_space = Conv2DSpace(shape=(32, 32),\n",
      "                       num_channels=3,\n",
      "                       axes=('c', 0, 1, 'b'))\n",
      "\n",
      "h2 = mlp.ConvRectifiedLinear(layer_name = 'h2',\n",
      "                     output_channels=64 ,\n",
      "                     irange= .05,\n",
      "                     kernel_shape= (5, 5),\n",
      "                     pool_shape= (4, 4),\n",
      "                     pool_stride= (2, 2),\n",
      "                     max_kernel_norm= 1.9365)\n",
      "\n",
      "h3 = mlp.ConvRectifiedLinear(layer_name = 'h3',\n",
      "                     output_channels=64 ,\n",
      "                     irange= .05,\n",
      "                     kernel_shape= (5, 5),\n",
      "                     pool_shape= (4, 4),\n",
      "                     pool_stride= (2, 2),\n",
      "                     max_kernel_norm= 1.9365)\n",
      "\n",
      "\n",
      "output = mlp.Softmax(layer_name='y',\n",
      "                     n_classes=2,\n",
      "                     irange=.005,\n",
      "                     max_col_norm=1.9365)\n",
      "\n",
      "layers = [h2, h3, output]\n",
      "\n",
      "#Define the model\n",
      "#Not sure if we need to modify this.\n",
      "mdl = mlp.MLP(layers,\n",
      "              input_space=in_space)\n",
      "\n",
      "\n",
      "#Not sure what this does from here to next comment.\n",
      "trainer = sgd.SGD(learning_rate=.17,\n",
      "                  batch_size=32,\n",
      "                  learning_rule=learning_rule.Momentum(.5),\n",
      "                  # Remember, default dropout is .5\n",
      "                  cost=Dropout(input_include_probs={'h2': .8},\n",
      "                               input_scales={'h2': 1.}),\n",
      "                  termination_criterion=EpochCounter(max_epochs=475),\n",
      "                  monitoring_dataset={'valid': tst,\n",
      "                                      'train': trn})\n",
      "\n",
      "preprocessor = Pipeline([GlobalContrastNormalization(scale=55.), ZCA()])\n",
      "trn.apply_preprocessor(preprocessor=preprocessor, can_fit=True)\n",
      "tst.apply_preprocessor(preprocessor=preprocessor, can_fit=False)\n",
      "serial.save('deepcuts_preprocessor.pkl', preprocessor)\n",
      "\n",
      "watcher = best_params.MonitorBasedSaveBest(\n",
      "    channel_name='valid_y_misclass',\n",
      "    save_path='deepcuts_maxout_zca.pkl')\n",
      "\n",
      "velocity = learning_rule.MomentumAdjustor(final_momentum=.65,\n",
      "                                          start=1,\n",
      "                                          saturate=250)\n",
      "\n",
      "decay = sgd.LinearDecayOverEpoch(start=1,\n",
      "                                 saturate=500,\n",
      "                                 decay_factor=.01)\n",
      "'''\n",
      "win = window_flip.WindowAndFlipC01B(pad_randomized=8,\n",
      "                                    window_shape=(32, 32),\n",
      "                                    randomize=[trn],\n",
      "                                    center=[tst])\n",
      "'''\n",
      "#Define experiment\n",
      "experiment = Train(dataset=trn,\n",
      "                   model=mdl,\n",
      "                   algorithm=trainer,\n",
      "                   extensions=[watcher, velocity, decay])\n",
      "\n",
      "#Run experiment\n",
      "experiment.main_loop()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 1 movies: \n",
        "['anni005']\n",
        "('Gathered labels for ', 13, 'videos')\n",
        "[[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
        "(4, 3, 32, 32)\n",
        "9\n",
        "Found 1 movies: \n",
        "['anni005']\n",
        "('Gathered labels for ', 13, 'videos')\n",
        "[[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
        "(4, 3, 32, 32)\n",
        "9\n",
        "Input shape: (32, 32)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Detector space: (28, 28)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Output space: (13, 13)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Input shape: (13, 13)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Detector space: (9, 9)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Output space: (4, 4)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "computing zca of a (4, 3072) matrix\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cov estimate took 0.0522608757019 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "eigh() took 20.8840420246 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameter and initial learning rate summary:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\th2_W: 0.17\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\th2_b: 0.17\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\th3_W: 0.17\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\th3_b: 0.17\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tsoftmax_b: 0.17\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tsoftmax_W: 0.17\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Compiling sgd_update...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Compiling sgd_update done. Time elapsed: 42.408589 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compiling begin_record_entry...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compiling begin_record_entry done. Time elapsed: 0.564689 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitored channels: \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmomentum\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttotal_seconds_last_epoch\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_kernel_norms_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_kernel_norms_mean\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_kernel_norms_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_max_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_max_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_max_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_mean_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_mean_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_mean_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_min_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_min_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_min_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_range_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_range_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h2_range_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_kernel_norms_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_kernel_norms_mean\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_kernel_norms_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_max_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_max_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_max_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_mean_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_mean_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_mean_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_min_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_min_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_min_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_range_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_range_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_h3_range_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_objective\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_col_norms_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_col_norms_mean\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_col_norms_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_max_max_class\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_mean_max_class\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_min_max_class\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_misclass\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_nll\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_row_norms_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_row_norms_mean\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_y_row_norms_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttraining_seconds_this_epoch\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_kernel_norms_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_kernel_norms_mean\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_kernel_norms_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_max_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_max_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_max_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_mean_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_mean_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_mean_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_min_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_min_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_min_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_range_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_range_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h2_range_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_kernel_norms_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_kernel_norms_mean\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_kernel_norms_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_max_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_max_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_max_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_mean_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_mean_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_mean_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_min_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_min_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_min_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_range_x_max_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_range_x_mean_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_h3_range_x_min_u\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_objective\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_col_norms_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_col_norms_mean\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_col_norms_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_max_max_class\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_mean_max_class\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_min_max_class\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_misclass\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_nll\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_row_norms_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_row_norms_mean\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_y_row_norms_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Compiling accum...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "graph size: 276\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "graph size: 272\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Compiling accum done. Time elapsed: 29.251772 seconds\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "VectorSpace(dim=9, dtype=float64) with total dimension 9 can't format a batch into VectorSpace(dim=2, dtype=float64)because its total dimension is 2",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-43-f8182c1e1a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m#Run experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/train.pyc\u001b[0m in \u001b[0;36mmain_loop\u001b[0;34m(self, time_budget)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mdata_specs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNullSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     dataset=self.model.monitor._datasets[0])\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mextension_continue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks_and_monitoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# First check if the model is already beyond the stop criteria of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/train.pyc\u001b[0m in \u001b[0;36mrun_callbacks_and_monitoring\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mextension\u001b[0m \u001b[0mwants\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstop\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mcontinue_learning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/monitor.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mactual_ne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyiterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                     \u001b[0;31m# X is a flat (not nested) tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_prereqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/utils/iteration.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallback_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/utils/iteration.pyc\u001b[0m in \u001b[0;36m_fallback_next\u001b[0;34m(self, next_index)\u001b[0m\n\u001b[1;32m    995\u001b[0m         return tuple(\n\u001b[1;32m    996\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msafe_izip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         )\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/utils/iteration.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((data, fn))\u001b[0m\n\u001b[1;32m    995\u001b[0m         return tuple(\n\u001b[1;32m    996\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msafe_izip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         )\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/utils/iteration.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(batch, dspace, sp)\u001b[0m\n\u001b[1;32m    945\u001b[0m                 \u001b[0;31m# of the loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 fn = (lambda batch, dspace=dspace, sp=sp:\n\u001b[0;32m--> 947\u001b[0;31m                       dspace.np_format_as(batch, sp))\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/space/__init__.pyc\u001b[0m in \u001b[0;36mnp_format_as\u001b[0;34m(self, batch, space)\u001b[0m\n\u001b[1;32m    484\u001b[0m         return self._format_as(is_numeric=True,\n\u001b[1;32m    485\u001b[0m                                \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                                space=space)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/space/__init__.pyc\u001b[0m in \u001b[0;36m_format_as\u001b[0;34m(self, is_numeric, batch, space)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# checks if self and space have compatible sizes for formatting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_as_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/alex/pylearn2/pylearn2/space/__init__.pyc\u001b[0m in \u001b[0;36m_check_sizes\u001b[0;34m(self, space)\u001b[0m\n\u001b[1;32m    498\u001b[0m                              \u001b[0;34m\" can't format a batch into \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"because its total dimension is \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                              str(other_dimension))\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: VectorSpace(dim=9, dtype=float64) with total dimension 9 can't format a batch into VectorSpace(dim=2, dtype=float64)because its total dimension is 2"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('done')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}