{
 "metadata": {
  "name": "",
  "signature": "sha256:7a1fe3f5aca9a561715e7506b0a99fe60df4836ebdad95cd5337f2990ac81c3d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Deepcuts CNN"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a fully self-contained CNN Architecture for shot boundary detection. The code performs the following tasks:\n",
      "\n",
      "- Create a FrameDataSet class inheriting 'DenseDesignMatrix' to hold the data. The Pylearn2 CNN architecture expects a DenseDesignMatrix container.\n",
      "\n",
      "- Read all data files\n",
      "\n",
      "- Create an ndarray, frame_pair, of dimension Channel x Height x Width for the data of each frame-pair in both the train & test set. The format of the array is as follows:\n",
      "    - Channel = The signal type (e.g. horizontal flow)\n",
      "    - Height = The height of the image \n",
      "    - Width = The Width of the images\n",
      "\n",
      "- Put all of the frame_pairs into a FrameDataSet\n",
      "\n",
      "- Define the network architecture using the YAML markup language\n",
      "\n",
      "- Run the CNN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dependencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/pylearn2/> Pylearn2</a>\n",
      "\n",
      "- <a href=http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux/#axzz3ZD4QUCPt> CUDA (optional)</a>\n",
      "    - <a href=http://www.quantstart.com/articles/Installing-Nvidia-CUDA-on-Ubuntu-14-04-for-Linux-GPU-Computing> A helpful CUDA install guide </a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/theano/tutorial/using_gpu.html> Theano GPU Settings </a> (if using cuda)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References & Helpful Links"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- <a href=http://deeplearning.net/software/pylearn2/tutorial/index.html#tutorial> Python Quick Start Tutorial </a>\n",
      "- <a href=http://deeplearning.net/software/pylearn2/yaml_tutorial/index.html#yaml-tutorial> YAML for Pylearn2</a>\n",
      "- <a href=http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/convolutional_network/convolutional_network.ipynb>iPython Notebook CNN Tutorial</a>\n",
      "- <a href=http://nbviewer.ipython.org/gist/cancan101/ea563e394ea968127e0e > Fully Contained iPython Notebook CNN </a>\n",
      "- <a href=https://github.com/kastnerkyle/kaggle-cifar10/blob/master/kaggle_dataset.py> Sample Dataset Class </a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Put all of the imports here\n",
      "#NOTE: Importing all of pylearn2 is VERY slow. \n",
      "# - Import only the needed components.\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from theano import config\n",
      "\n",
      "from theano.compat.six.moves import xrange\n",
      "from pylearn2.datasets import dense_design_matrix\n",
      "from pylearn2.datasets import control\n",
      "from pylearn2.datasets import cache\n",
      "from pylearn2.utils import serial\n",
      "from pylearn2.utils.rng import make_np_rng\n",
      "\n",
      "from os import listdir\n",
      "from os.path import isfile, isdir, join, basename, splitext\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Check which device theano uses (gpu or cpu\n",
      "print theano.config.device"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cpu\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Define Global Parameters\n",
      "DATA_ROOT = '/path/to/data/root'\n",
      "\n",
      "FORCED_HEIGHT = 512\n",
      "FORCED_WIDTH = 512\n",
      "\n",
      "#Signals that should be converted to single channel\n",
      "NEEDS_COLOR_CONVERSION = ['h_flow', 'v_flow', 'luminance'] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get all files in directory\n",
      "def get_all_files(path):\n",
      "    files = [f for f in listdir(path) if isfile(join(path, f)) and \\\n",
      "             f[0] != '.' ] #ignore hidden files\n",
      "    return files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get all subdirectories in a directory\n",
      "def get_all_dirs(path):\n",
      "    folders = [f for f in listdir(path) if isdir(join(path, f)) and \\\n",
      "               f[0] != '.'] #ignore hiddin directories\n",
      "    return folders"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Each pixel value is the average from rgb\n",
      "#This is for mathematical accuracy\n",
      "#This is NOT for producing visually accurate rgb conversion\n",
      "def convert(signal_type, im):\n",
      "    image = im\n",
      "    if path in NEEDS_COLOR_CONVERSION:\n",
      "        h,w,ch = im.shape()\n",
      "        output = np.zeros([h,w])\n",
      "        for i in range(0, ch):\n",
      "            output = output + im[:,:,i]\n",
      "        \n",
      "        image = output / ch        \n",
      "    #After color conversion, we reshape for CNN input. \n",
      "            \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create the FramePair class\n",
      "class FramePair:\n",
      "    \n",
      "    def __init__(self, path, frame_num):\n",
      "        frame_string = str(frame_num).zfill(6) + '.jpg'\n",
      "        signals = get_all_dirs(path)     "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create the FrameDataSet Class\n",
      "class FrameDataSet(dense_design_matrix.DenseDesignMatrix):\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.all_frames = None\n",
      "        self.h = -1\n",
      "        self.w = -1\n",
      "        self.ch = -1\n",
      "                                         \n",
      "    def add_container(self, im_h, im_w, im_ch):\n",
      "        assert (im_h > 0 and im_w > 0 and im_ch > 0), \\\n",
      "            \"Signals must have a non-zero height, width, and channels.\"\n",
      "        self.all_frames = np.empty([1, im_h, im_w, im_ch])\n",
      "        self.h = im_h\n",
      "        self.w = im_w\n",
      "        self.ch = im_ch\n",
      "                                    \n",
      "    def add_datum(self, dat):\n",
      "        h,w,ch = dat.shape()\n",
      "        if self.all_frames == None:\n",
      "            add_container(h, w, ch)\n",
      "            self.all_frames[0] = dat\n",
      "        else:\n",
      "            assert (h == self.h and w == self.w and ch == self.ch), \\\n",
      "                \"Attempted to add data with unexpected dimensions\"\n",
      "            self.all_frames = np.vstack(self.all_frames, dat)\n",
      "            \n",
      "        \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Read the data files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#For every datafile, create a FramePair"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Put all of the FramePairs into a FrameDataSet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Define the network architecture (See MNIST YAML & Kaggle YAML)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Run the CNN"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}